# Cuántas componentes hay realmente en el modelo
nComp_total <- nrow(myplsC@modelDF)
# Límite superior: 5 o lo que tenga el modelo, lo que sea menor
nComp <- min(5, nComp_total)
# Extraer solo los valores válidos
R2Y_vals <- myplsC@modelDF$`R2Y(cum)`[1:nComp]
Q2_vals  <- myplsC@modelDF$`Q2(cum)`[1:nComp]
# Gráfico limpio hasta la componente 5 (o menos si no hay tantas)
plot(1:nComp, R2Y_vals, type = "o", pch = 16, col = "blue3",
lwd = 2, xlab = "Components", ylab = "", ylim = c(0, 1),
main = "PLS model: Olive oil")
lines(1:nComp, Q2_vals, type = "o", pch = 16, col = "red3", lwd = 2)
abline(h = 0.5, col = "red3", lty = 2)
legend("bottomleft", c("R2Y", "Q2"), lwd = 2,
col = c("blue3", "red3"), bty = "n")
A <- 2
mypls = opls(x = X, y = Y, predI = A, crossvalI = nrow(X), scaleC = "standard")
mypred = predict(mypls)
caret::confusionMatrix(mypred, Y)
plot(mypls, typeVc = "x-score",
parAsColFcVn = Y,
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(1:nrow(X)))
par(mfrow = c(1,2))
plot(x = mypls, typeVc = "x-score",
parAsColFcVn = Y,                   # Colorear por grupo
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(Y),         # Etiquetar con valores de clase
parPaletteVc = NA,
parTitleL = TRUE,
parCexMetricN = NA)
plot(x = mypls, typeVc = "x-loading",
parCexN = 0.8, parCompVi = c(1, 2), parPaletteVc = NA,
parTitleL = TRUE, parCexMetricN = NA)
data_plot <- rbind(data.frame(mypls@weightStarMN, space = "X"),
data.frame(mypls@cMN, space = "Y"))
data_plot <- cbind(data_plot, variable = rownames(data_plot))
ggplot(data_plot, aes(x = p1, y = p2, col = space, shape = space)) +
geom_point() +
geom_text_repel(label=rownames(data_plot), size = 3, max.overlaps = Inf) +
xlim(min(data_plot$p1)-0.2,max(data_plot$p1)+0.2) +
ylim(min(data_plot$p2)-0.2,max(data_plot$p2)+0.2) +
coord_fixed(ratio = 1) +
theme_bw() +
geom_vline(xintercept = 0) +
geom_hline(yintercept = 0) +
xlab("w*c (comp 1)") +
ylab("w*c (comp 2)")
# Obtener VIPs y seleccionar las top 20
vip <- sort(mypls@vipVn, decreasing = TRUE)
top_vip_names <- names(vip)[1:20]
# Crear data_plot para X y Y
data_plot <- rbind(
data.frame(mypls@weightStarMN, space = "X"),
data.frame(mypls@cMN, space = "Y")
)
data_plot$variable <- rownames(data_plot)
colnames(data_plot)[1:2] <- c("p1", "p2")
# Filtrar solo las X de interés + todas las Y
data_plot_top <- subset(data_plot, (space == "Y") | (space == "X" & variable %in% top_vip_names))
# Graficar solo variables relevantes
ggplot(data_plot_top, aes(x = p1, y = p2, col = space, shape = space)) +
geom_point() +
geom_text_repel(aes(label = variable), size = 3, max.overlaps = Inf) +
xlim(min(data_plot$p1) - 0.2, max(data_plot$p1) + 0.2) +
ylim(min(data_plot$p2) - 0.2, max(data_plot$p2) + 0.2) +
coord_fixed(ratio = 1) +
theme_bw() +
geom_vline(xintercept = 0) +
geom_hline(yintercept = 0) +
xlab("w*c (comp 1)") +
ylab("w*c (comp 2)") +
ggtitle("Biplot: top 20 X variables by VIP")
# Obtener variables con VIP > 1
# Extraer VIPs
vip <- mypls@vipVn
# Crear data.frame ordenado
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# Ordenar de mayor a menor
vip_df <- vip_df[order(-vip_df$VIP), ]
# Mostrar
head(vip_df,50)  # muestra las 20 más importantes
# Si aún no existe:
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
vip_df <- vip_df[order(-vip_df$VIP), ]
# (Opcional) Limitar a las 20 más importantes
vip_top <- head(vip_df, 20)
vip_top$variable <- factor(vip_top$variable, levels = vip_top$variable)  # para ordenar bien
# Gráfico bonito
ggplot(vip_top, aes(x = variable, y = VIP)) +
geom_col(fill = "steelblue") +
geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
coord_flip() +
labs(title = "Top 20 variables por VIP",
x = "", y = "Valor VIP") +
theme_minimal(base_size = 13) +
theme(axis.text.y = element_text(size = 12),
plot.title = element_text(hjust = 0.5))
par(mfrow = c(1,2))
plot(x = mypls, typeVc = "x-score",
parAsColFcVn = Y,                   # Colorear por grupo
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(Y),         # Etiquetar con valores de clase
parPaletteVc = NA,
parTitleL = TRUE,
parCexMetricN = NA)
plot(x = mypls, typeVc = "x-loading",
parCexN = 0.8, parCompVi = c(1, 2), parPaletteVc = NA,
parTitleL = TRUE, parCexMetricN = NA)
par(mfrow = c(1,2))
plot(x = mypls, typeVc = "x-score",
parAsColFcVn = Y,                   # Colorear por grupo
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(Y),         # Etiquetar con valores de clase
parPaletteVc = NA,
parTitleL = TRUE,
parCexMetricN = NA)
plot(x = mypls, typeVc = "x-loading",
parCexN = 0.8, parCompVi = c(1, 2), parPaletteVc = NA,
parTitleL = TRUE, parCexMetricN = NA)
par(mfrow = c(1,2))
plot(x = mypls, typeVc = "x-score",
parAsColFcVn = Y,                   # Colorear por grupo
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(Y),         # Etiquetar con valores de clase
parPaletteVc = NA,
parTitleL = TRUE,
parCexMetricN = NA)
plot(x = mypls, typeVc = "x-loading",
parCexN = 0.8, parCompVi = c(1, 2), parPaletteVc = NA,
parTitleL = TRUE, parCexMetricN = NA)
# 1. Extraer VIPs del modelo original
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# 2. Filtrar variables con VIP > 1
vars_vip1 <- vip_df$variable[vip_df$VIP > 1]
# 3. Reconstruir X reducido solo con esas variables
X_reducido <- X[, vars_vip1]
# 4. Nuevo modelo PLS-DA con solo VIP > 1
mypls_vip <- opls(
x = X_reducido,
y = Y,
predI = NA,                         # Selección automática del nº de componentes
crossvalI = nrow(X_reducido),       # Leave-One-Out
scaleC = "standard",
fig.pdfC = "none"
)
# 5. Matriz de confusión del nuevo modelo
cat("\nMatriz de confusión (modelo con VIP > 1):\n")
print(table(Predicted = mypls_vip@predDf$`y`, Reference = Y))
# 1. Extraer VIPs del modelo original
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# 2. Filtrar variables con VIP > 1
vars_vip1 <- vip_df$variable[vip_df$VIP > 1]
# 3. Reconstruir X reducido solo con esas variables
X_reducido <- X[, vars_vip1]
# 4. Nuevo modelo PLS-DA con solo VIP > 1
mypls_vip <- opls(
x = X_reducido,
y = Y,
predI = NA,                         # Selección automática del nº de componentes
crossvalI = nrow(X_reducido),       # Leave-One-Out
scaleC = "standard",
fig.pdfC = "none"
)
# Matriz de confusión usando predicciones internas del modelo
pred <- mypls_vip@yHatDc  # Predicciones internas
# 1. Extraer VIPs del modelo original
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# 2. Filtrar variables con VIP > 1
vars_vip1 <- vip_df$variable[vip_df$VIP > 1]
# 3. Reconstruir X reducido solo con esas variables
X_reducido <- X[, vars_vip1]
# 4. Nuevo modelo PLS-DA con solo VIP > 1
mypls_vip <- opls(
x = X_reducido,
y = Y,
predI = NA,                         # Selección automática del nº de componentes
crossvalI = nrow(X_reducido),       # Leave-One-Out
scaleC = "standard",
fig.pdfC = "none"
)
# Obtener predicciones del modelo VIP
pred <- mypls_vip@modelDf$y
library(ropls)
# 1. Agrupar clases si corresponde
data$X1ª_eval[data$X1ª_eval == "PS"] <- "EE"
# 2. Definir Y como factor (clase a predecir)
Y <- as.factor(data$X1ª_eval)
# 3. Preparar X completo (numérico)
X <- data[, !(names(data) %in% c("X1ª_eval", "Mejor_resp"))]
X <- X[, sapply(X, is.numeric)]
X <- as.matrix(X)
# 4. Ajustar primer modelo completo (para obtener VIPs)
modelo_inicial <- opls(
x = X,
y = Y,
predI = NA,
crossvalI = nrow(X),
scaleC = "standard",
fig.pdfC = "none"
)
# 5. Extraer variables con VIP > 1
vip <- modelo_inicial@vipVn
vars_vip1 <- names(vip[vip > 1])
# 6. Crear X reducido con solo esas variables
X_reducido <- X[, vars_vip1]
# 7. Entrenar nuevo modelo solo con variables VIP > 1
modelo_vip <- opls(
x = X_reducido,
y = Y,
predI = NA,
crossvalI = nrow(X_reducido),
scaleC = "standard",
fig.pdfC = "none"
)
# 8. Predicciones del modelo VIP (clasificación)
pred <- factor(modelo_vip@modelDf$y, levels = levels(Y))
# 1. Extraer VIPs del modelo original
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# 2. Filtrar variables con VIP > 1
vars_vip1 <- vip_df$variable[vip_df$VIP > 1]
# 3. Reconstruir X reducido solo con esas variables
X_reducido <- X[, vars_vip1]
# 4. Nuevo modelo PLS-DA con solo VIP > 1
mypls_vip <- opls(
x = X_reducido,
y = Y,
predI = NA,                         # Selección automática del nº de componentes
crossvalI = nrow(X_reducido),       # Leave-One-Out
scaleC = "standard",
fig.pdfC = "none"
)
# Obtener predicciones del modelo VIP
pred <- mypls_vip@modelDf$y
# 1. Extraer VIPs del modelo original
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# 2. Filtrar variables con VIP > 1
vars_vip1 <- vip_df$variable[vip_df$VIP > 1]
# 3. Reconstruir X reducido solo con esas variables
X_reducido <- X[, vars_vip1]
# 4. Nuevo modelo PLS-DA con solo VIP > 1
mypls_vip <- opls(
x = X_reducido,
y = Y,
predI = NA,                         # Selección automática del nº de componentes
crossvalI = nrow(X_reducido),       # Leave-One-Out
scaleC = "standard",
fig.pdfC = "none"
)
# Obtener predicciones del modelo VIP
pred <- mypls_vip@modelDf$y
# 1. Extraer VIPs del modelo original
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# 2. Filtrar variables con VIP > 1
vars_vip1 <- vip_df$variable[vip_df$VIP > 1]
# 3. Reconstruir X reducido solo con esas variables
X_reducido <- X[, vars_vip1]
# 4. Nuevo modelo PLS-DA con solo VIP > 1
mypls_vip <- opls(
x = X_reducido,
y = Y,
predI = NA,                         # Selección automática del nº de componentes
crossvalI = nrow(X_reducido),       # Leave-One-Out
scaleC = "standard",
fig.pdfC = "none"
)
# Obtener predicciones del modelo VIP
pred <- mypls_vip@modelDf$y
```{}
# Si aún no existe:
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
vip_df <- vip_df[order(-vip_df$VIP), ]
# (Opcional) Limitar a las 20 más importantes
vip_top <- head(vip_df, 20)
vip_top$variable <- factor(vip_top$variable, levels = vip_top$variable)  # para ordenar bien
# Gráfico bonito
ggplot(vip_top, aes(x = variable, y = VIP)) +
geom_col(fill = "steelblue") +
geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
coord_flip() +
labs(title = "Top 20 variables por VIP",
x = "", y = "Valor VIP") +
theme_minimal(base_size = 13) +
theme(axis.text.y = element_text(size = 12),
plot.title = element_text(hjust = 0.5))
knitr::opts_chunk$set(echo = TRUE)
# Instala si no los tienes
install.packages(c("readxl", "randomForest", "caret", "fastshap", "dplyr"))
# Cargar librerías
library(readxl)
install.packages(c("readxl", "randomForest", "caret", "fastshap", "dplyr"))
knitr::opts_chunk$set(echo = TRUE)
# Instala si no los tienes
#install.packages(c("readxl", "randomForest", "caret", "fastshap", "dplyr"))
# Cargar librerías
library(readxl)
# Instala si no los tienes
#install.packages(c("readxl", "randomForest", "caret", "fastshap", "dplyr"))
# Cargar librerías
library(randomForest)
library(caret)
library(fastshap)
library(dplyr)
# Leer Excel
data <- read_excel("datos_PCA.xlsx")
# Leer Excel
data <- read_excel("datos_PCA.xlsx")
# Instala si no los tienes
#install.packages(c("readxl", "randomForest", "caret", "fastshap", "dplyr"))
# Cargar librerías
library(openxlsx)
library(randomForest)
library(caret)
library(fastshap)
library(dplyr)
# Leer Excel
data <- read.xlsx("datos_PCA.xlsx")
# Re-codificar clases si es necesario
data$X1ª_eval[data$X1ª_eval == "PS"] <- "EE"
# Definir variable respuesta como factor
Y <- as.factor(data$X1ª_eval)
# Eliminar variables respuesta de los predictores
X <- data %>%
select(-c(`X1ª_eval`, `Mejor_resp`)) %>%
select(where(is.numeric))  # solo columnas numéricas
# Convertir a data.frame para fastshap
X <- as.data.frame(X)
# Control de validación cruzada LOO
ctrl <- trainControl(method = "LOOCV", classProbs = TRUE, savePredictions = "final")
# Entrenar modelo
set.seed(123)
modelo_rf <- train(
x = X,
y = Y,
method = "rf",
trControl = ctrl,
importance = TRUE
)
# Crear función predictora
predictor <- function(object, newdata) {
predict(object, newdata = newdata, type = "prob")
}
# Calcular SHAP para cada clase (ejemplo para clase "PE")
shap_vals <- fastshap::explain(
object = modelo_rf$finalModel,
feature_names = names(X),
X = X,
pred_wrapper = function(object, newdata) {
predict(object, newdata, type = "prob")[, "PE"]  # cambia "PE" si necesitas otra clase
},
nsim = 100  # número de permutaciones SHAP (ajustable)
)
# Visualizar importancia SHAP promedio
mean_shap <- colMeans(abs(shap_vals))
mean_shap <- sort(mean_shap, decreasing = TRUE)
# Mostrar top 20
print(head(mean_shap, 20))
library(ggplot2)
df_shap <- data.frame(
Variable = names(mean_shap),
SHAP_Importance = mean_shap
)
ggplot(head(df_shap, 20), aes(x = reorder(Variable, SHAP_Importance), y = SHAP_Importance)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Importancia SHAP (Top 20)", x = "Variable", y = "SHAP promedio") +
theme_minimal()
# Mostrar resumen del modelo (incluye accuracy promedio y SD)
print(modelo_rf)
library(caret)
# Obtener predicciones vs valores reales
pred <- modelo_rf$pred$pred
obs  <- modelo_rf$pred$obs
# Asegurar que tienen mismos niveles
pred <- factor(pred, levels = levels(obs))
# Evaluar
cm <- confusionMatrix(pred, obs)
print(cm)
# Leer Excel
data <- read.xlsx("datos_PCA.xlsx")
# 1. Preparar X e Y
data$X1ª_eval[data$X1ª_eval == "PS"] <- "EE"
Y <- as.factor(data$X1ª_eval)
X <- data %>%
select(-c(`X1ª_eval`, `Mejor_resp`)) %>%
select(where(is.numeric)) %>%
as.data.frame()
# 2. Definir grid de hiperparámetros a probar
grid_rf <- expand.grid(mtry = seq(2, floor(sqrt(ncol(X)) * 2), by = 1))
# 3. Control de validación cruzada tipo LOO
ctrl_loo <- trainControl(
method = "LOOCV",
classProbs = TRUE,
savePredictions = "final"
)
# 4. Entrenamiento optimizado
set.seed(123)
modelo_rf_tuned <- train(
x = X,
y = Y,
method = "rf",
trControl = ctrl_loo,
tuneGrid = grid_rf,
importance = TRUE,
ntree = 500  # puedes subir o ajustar esto si hace falta
)
# 5. Ver mejor mtry y rendimiento
print(modelo_rf_tuned)
# Confusion matrix y métricas
confusionMatrix(modelo_rf_tuned$pred$pred, modelo_rf_tuned$pred$obs)
knitr::opts_chunk$set(echo = TRUE)
# Instala si no los tienes
#install.packages(c("readxl", "randomForest", "caret", "fastshap", "dplyr"))
# Cargar librerías
library(openxlsx)
library(randomForest)
library(caret)
library(fastshap)
library(dplyr)
# Leer Excel
data <- read.xlsx("datos_PCA.xlsx")
# 1. Preparar X e Y
data$X1ª_eval[data$X1ª_eval == "PS"] <- "EE"
Y <- as.factor(data$X1ª_eval)
X <- data %>%
select(-c(`X1ª_eval`, `Mejor_resp`)) %>%
select(where(is.numeric)) %>%
as.data.frame()
# 2. Definir grid de hiperparámetros a probar
grid_rf <- expand.grid(mtry = seq(2, floor(sqrt(ncol(X)) * 2), by = 1))
# 3. Control de validación cruzada tipo LOO
ctrl_loo <- trainControl(
method = "LOOCV",
classProbs = TRUE,
savePredictions = "final"
)
# 4. Entrenamiento optimizado
set.seed(123)
modelo_rf_tuned <- train(
x = X,
y = Y,
method = "rf",
trControl = ctrl_loo,
tuneGrid = grid_rf,
importance = TRUE,
ntree = 10000  # puedes subir o ajustar esto si hace falta
)
# 5. Ver mejor mtry y rendimiento
print(modelo_rf_tuned)
# Confusion matrix y métricas
confusionMatrix(modelo_rf_tuned$pred$pred, modelo_rf_tuned$pred$obs)
# Confusion matrix y métricas
confusionMatrix(modelo_rf_tuned$pred$pred, modelo_rf_tuned$pred$obs)
# Crear función predictora
predictor <- function(object, newdata) {
predict(object, newdata = newdata, type = "prob")
}
# Calcular SHAP para cada clase (ejemplo para clase "PE")
shap_vals <- fastshap::explain(
object = modelo_rf$finalModel,
feature_names = names(X),
X = X,
pred_wrapper = function(object, newdata) {
predict(object, newdata, type = "prob")[, "PE"]  # cambia "PE" si necesitas otra clase
},
nsim = 100  # número de permutaciones SHAP (ajustable)
)
