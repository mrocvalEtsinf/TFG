coef_lda$variable <- rownames(coef_lda)
# Ordenar por contribución absoluta a LD1
coef_lda <- coef_lda[order(abs(coef_lda$LD1), decreasing = TRUE), ]
# Seleccionar las top 20 variables
top_vars_lda <- head(coef_lda$variable, 20)
# Preparar nuevo data.frame con Y + top 20 variables
df_lda_top <- data.frame(Y = data$X1ª_eval, data[, top_vars_lda])
set.seed(123)
train_control <- trainControl(
method = "LOOCV",
classProbs = TRUE,
savePredictions = "final"
)
modelo_lda_top <- train(
Y ~ .,
data = df_lda_top,
method = "lda",
trControl = train_control
)
# Métricas de rendimiento
print(modelo_lda_top)
# Matriz de confusión
confusionMatrix(modelo_lda_top$pred$pred, modelo_lda_top$pred$obs)
# Entrenar LDA manual con solo top vars
modelo_lda_top_manual <- lda(Y ~ ., data = df_lda_top)
# Proyectar en funciones discriminantes
lda_pred_top <- predict(modelo_lda_top_manual)
lda_scores_top <- data.frame(
LD1 = lda_pred_top$x[,1],
LD2 = lda_pred_top$x[,2],
Clase = df_lda_top$Y
)
# Plot
ggplot(lda_scores_top, aes(x = LD1, y = LD2, color = Clase)) +
geom_point(size = 3, alpha = 0.8) +
stat_ellipse() +
theme_minimal(base_size = 14) +
labs(title = "LDA reducido: top 20 variables",
x = "LD1", y = "LD2")
# Librerías
library(ggplot2)
library(reshape2)
library(viridis)
# Matriz de correlación
corr_matrix <- cor(X_top, use = "pairwise.complete.obs")
# Librerías
library(ggplot2)
library(reshape2)
library(viridis)
# Matriz de correlación
corr_matrix <- cor(X_top, use = "pairwise.complete.obs")
# Librerías
library(ggplot2)
library(reshape2)
library(viridis)
coef_lda <- as.data.frame(modelo_lda_manual$scaling)
coef_lda$variable <- rownames(coef_lda)
coef_lda <- coef_lda[order(abs(coef_lda$LD1), decreasing = TRUE), ]
top_vars <- head(coef_lda$variable, 20)
X_top <- data[, top_vars]
# Matriz de correlación
corr_matrix <- cor(X_top, use = "pairwise.complete.obs")
# Convertir a formato largo
corr_df <- melt(corr_matrix)
# Filtrar correlaciones altas y quitar la diagonal
corr_df_fuerte <- subset(corr_df, abs(value) >= 0.9 & Var1 != Var2)
# Gráfico con valores de correlación
ggplot(corr_df_fuerte, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
geom_text(aes(label = round(value, 2)), size = 3, color = "white") +  # ← etiquetas
scale_fill_viridis(option = "C", limits = c(-1, 1)) +
theme_minimal(base_size = 13) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 11)) +
labs(title = "Correlaciones fuertes (≥ |0.9|) entre variables top LDA",
x = "", y = "", fill = "Correlación")
# Librerías
library(ggplot2)
library(reshape2)
library(viridis)
coef_lda <- as.data.frame(modelo_lda_manual$scaling)
coef_lda$variable <- rownames(coef_lda)
coef_lda <- coef_lda[order(abs(coef_lda$LD1), decreasing = TRUE), ]
top_vars <- head(coef_lda$variable, 20)
X_top <- data[, top_vars]
# Matriz de correlación
corr_matrix <- cor(X_top, use = "pairwise.complete.obs")
# Convertir a formato largo
corr_df <- melt(corr_matrix)
# Filtrar correlaciones altas y quitar la diagonal
corr_df_fuerte <- subset(corr_df, abs(value) >= 0.8 & Var1 != Var2)
# Gráfico con valores de correlación
ggplot(corr_df_fuerte, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
geom_text(aes(label = round(value, 2)), size = 3, color = "white") +  # ← etiquetas
scale_fill_viridis(option = "C", limits = c(-1, 1)) +
theme_minimal(base_size = 13) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 11)) +
labs(title = "Correlaciones fuertes (≥ |0.9|) entre variables top LDA",
x = "", y = "", fill = "Correlación")
# Librerías
library(ggplot2)
library(reshape2)
library(viridis)
coef_lda <- as.data.frame(modelo_lda_manual$scaling)
coef_lda$variable <- rownames(coef_lda)
coef_lda <- coef_lda[order(abs(coef_lda$LD1), decreasing = TRUE), ]
top_vars <- head(coef_lda$variable, 20)
X_top <- data[, top_vars]
# Matriz de correlación
corr_matrix <- cor(X_top, use = "pairwise.complete.obs")
# Convertir a formato largo
corr_df <- melt(corr_matrix)
# Filtrar correlaciones altas y quitar la diagonal
corr_df_fuerte <- subset(corr_df, abs(value) >= 0.6 & Var1 != Var2)
# Gráfico con valores de correlación
ggplot(corr_df_fuerte, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
geom_text(aes(label = round(value, 2)), size = 3, color = "white") +  # ← etiquetas
scale_fill_viridis(option = "C", limits = c(-1, 1)) +
theme_minimal(base_size = 13) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 11)) +
labs(title = "Correlaciones fuertes (≥ |0.9|) entre variables top LDA",
x = "", y = "", fill = "Correlación")
# Cargar librerías necesarias
library(caret)
library(MASS)
# Crear nuevo dataset sin variables colineales
vars_a_eliminar <- c("Leukocytes_cv", "Stage", "Albumin_media")
# X: seleccionamos todas las variables numéricas menos las eliminadas y variables respuesta
X_filtrado <- data[, !(names(data) %in% c("X1ª_eval", "Mejor_resp", vars_a_eliminar))]
X_filtrado <- X_filtrado[, sapply(X_filtrado, is.numeric)]
# Y: variable respuesta
Y <- as.factor(data$`X1ª_eval`)
# Construimos data.frame final
df_lda_final <- data.frame(Y, X_filtrado)
# Entrenamiento del modelo LDA con validación cruzada Leave-One-Out
set.seed(123)
modelo_lda_final <- train(
Y ~ .,
data = df_lda_final,
method = "lda",
trControl = trainControl(
method = "LOOCV",
classProbs = TRUE,
savePredictions = "final"
)
)
# Resultados
print(modelo_lda_final)
confusionMatrix(modelo_lda_final$pred$pred, modelo_lda_final$pred$obs)
set.seed(123)
train_control <- trainControl(
method = "LOOCV",
classProbs = TRUE,
savePredictions = "final"
)
modelo_lda_top <- train(
Y ~ .,
data = df_lda_top,
method = "lda",
trControl = train_control
)
# Métricas de rendimiento
print(modelo_lda_top)
# Matriz de confusión
confusionMatrix(modelo_lda_top$pred$pred, modelo_lda_top$pred$obs)
knitr::opts_chunk$set(echo = TRUE)
# Cargar librerías necesarias
library(openxlsx)
library(dplyr)
library(caret)
library(MASS)
# Cargar datos desde Excel
data <- read.xlsx("datos_PCA.xlsx")
# Convertir variable respuesta a factor
data$X1ª_eval <- as.factor(data$X1ª_eval)
# Eliminar variables de respuesta no deseadas
X <- data[, !(names(data) %in% c("X1ª_eval", "Mejor_resp"))]
# Quedarnos solo con variables numéricas
X <- X[, sapply(X, is.numeric)]
# Combinar con Y
df_lda <- data.frame(Y = data$X1ª_eval, X)
set.seed(123)
train_control <- trainControl(
method = "LOOCV",        # Leave-One-Out CV
classProbs = TRUE,       # Activar probabilidades
savePredictions = "final"
)
modelo_lda <- train(
Y ~ .,
data = df_lda,
method = "lda",
trControl = train_control
)
# Resumen de métricas
print(modelo_lda)
# Matriz de confusión
confusionMatrix(modelo_lda$pred$pred, modelo_lda$pred$obs)
# Entrenar LDA manualmente para obtener los scores
modelo_lda_manual <- lda(Y ~ ., data = df_lda)
# Proyectar los datos en las funciones discriminantes
lda_pred <- predict(modelo_lda_manual)
# Crear data.frame con los scores
lda_scores <- data.frame(
LD1 = lda_pred$x[,1],
LD2 = lda_pred$x[,2],
Clase = df_lda$Y
)
# Plot
library(ggplot2)
ggplot(lda_scores, aes(x = LD1, y = LD2, color = Clase)) +
geom_point(size = 3, alpha = 0.8) +
stat_ellipse() +
theme_minimal(base_size = 14) +
labs(title = "LDA: representación de funciones discriminantes",
x = "LD1", y = "LD2")
# Coeficientes de las funciones discriminantes
coef_lda <- as.data.frame(modelo_lda_manual$scaling)
coef_lda$variable <- rownames(coef_lda)
coef_lda <- coef_lda[order(abs(coef_lda$LD1), decreasing = TRUE), ]
head(coef_lda, 20)  # Top 20
# Coeficientes ordenados por importancia en LD1
coef_lda <- as.data.frame(modelo_lda_manual$scaling)
coef_lda$variable <- rownames(coef_lda)
# Ordenar por contribución absoluta a LD1
coef_lda <- coef_lda[order(abs(coef_lda$LD1), decreasing = TRUE), ]
# Seleccionar las top 20 variables
top_vars_lda <- head(coef_lda$variable, 20)
# Preparar nuevo data.frame con Y + top 20 variables
df_lda_top <- data.frame(Y = data$X1ª_eval, data[, top_vars_lda])
set.seed(123)
train_control <- trainControl(
method = "LOOCV",
classProbs = TRUE,
savePredictions = "final"
)
modelo_lda_top <- train(
Y ~ .,
data = df_lda_top,
method = "lda",
trControl = train_control
)
# Métricas de rendimiento
print(modelo_lda_top)
# Matriz de confusión
confusionMatrix(modelo_lda_top$pred$pred, modelo_lda_top$pred$obs)
# Entrenar LDA manual con solo top vars
modelo_lda_top_manual <- lda(Y ~ ., data = df_lda_top)
# Proyectar en funciones discriminantes
lda_pred_top <- predict(modelo_lda_top_manual)
lda_scores_top <- data.frame(
LD1 = lda_pred_top$x[,1],
LD2 = lda_pred_top$x[,2],
Clase = df_lda_top$Y
)
# Plot
ggplot(lda_scores_top, aes(x = LD1, y = LD2, color = Clase)) +
geom_point(size = 3, alpha = 0.8) +
stat_ellipse() +
theme_minimal(base_size = 14) +
labs(title = "LDA reducido: top 20 variables",
x = "LD1", y = "LD2")
# Librerías
library(ggplot2)
library(reshape2)
library(viridis)
coef_lda <- as.data.frame(modelo_lda_manual$scaling)
coef_lda$variable <- rownames(coef_lda)
coef_lda <- coef_lda[order(abs(coef_lda$LD1), decreasing = TRUE), ]
top_vars <- head(coef_lda$variable, 20)
X_top <- data[, top_vars]
# Matriz de correlación
corr_matrix <- cor(X_top, use = "pairwise.complete.obs")
# Convertir a formato largo
corr_df <- melt(corr_matrix)
# Filtrar correlaciones altas y quitar la diagonal
corr_df_fuerte <- subset(corr_df, abs(value) >= 0.6 & Var1 != Var2)
# Gráfico con valores de correlación
ggplot(corr_df_fuerte, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
geom_text(aes(label = round(value, 2)), size = 3, color = "white") +  # ← etiquetas
scale_fill_viridis(option = "C", limits = c(-1, 1)) +
theme_minimal(base_size = 13) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(size = 11)) +
labs(title = "Correlaciones fuertes (≥ |0.9|) entre variables top LDA",
x = "", y = "", fill = "Correlación")
# Cargar librerías necesarias
library(caret)
library(MASS)
# Crear nuevo dataset sin variables colineales
vars_a_eliminar <- c("Leukocytes_cv", "Stage", "Albumin_media")
# X: seleccionamos todas las variables numéricas menos las eliminadas y variables respuesta
X_filtrado <- data[, !(names(data) %in% c("X1ª_eval", "Mejor_resp", vars_a_eliminar))]
X_filtrado <- X_filtrado[, sapply(X_filtrado, is.numeric)]
# Y: variable respuesta
Y <- as.factor(data$`X1ª_eval`)
# Construimos data.frame final
df_lda_final <- data.frame(Y, X_filtrado)
# Entrenamiento del modelo LDA con validación cruzada Leave-One-Out
set.seed(123)
modelo_lda_final <- train(
Y ~ .,
data = df_lda_final,
method = "lda",
trControl = trainControl(
method = "LOOCV",
classProbs = TRUE,
savePredictions = "final"
)
)
# Resultados
print(modelo_lda_final)
confusionMatrix(modelo_lda_final$pred$pred, modelo_lda_final$pred$obs)
library(openxlsx)
# Crear data.frame con variables y valores VIP
vip_export <- vip_df[vip_df$VIP > 1, ]
library(openxlsx)
library(dplyr)
library(fastDummies)
library(ropls)
library(ggplot2)
library(ggrepel)
library(caret)
data <- read.xlsx("datos_PCA.xlsx")
# Preparar Y
Y <- as.factor(data$X1ª_eval)
# Preparar X
X <- data[, !(names(data) %in% c("X1ª_eval", "Mejor_resp"))]
X <- X[, sapply(X, is.numeric)]
X <- as.matrix(X)
# Modelo PLS-DA
mypls = opls(x = X, y = Y, predI = NA, crossvalI = nrow(X), scaleC = "standard",
fig.pdfC = "none")
maxNC = min(dim(X)); maxNC
myplsC = opls(x = X, y = Y, predI = 1, crossvalI = nrow(X),
scaleC = "standard", fig.pdfC = "none")
# Cuántas componentes hay realmente en el modelo
nComp_total <- nrow(myplsC@modelDF)
# Límite superior: 5 o lo que tenga el modelo, lo que sea menor
nComp <- min(5, nComp_total)
# Extraer solo los valores válidos
R2Y_vals <- myplsC@modelDF$`R2Y(cum)`[1:nComp]
Q2_vals  <- myplsC@modelDF$`Q2(cum)`[1:nComp]
# Gráfico limpio hasta la componente 5 (o menos si no hay tantas)
plot(1:nComp, R2Y_vals, type = "o", pch = 16, col = "blue3",
lwd = 2, xlab = "Components", ylab = "", ylim = c(0, 1),
main = "PLS model")
lines(1:nComp, Q2_vals, type = "o", pch = 16, col = "red3", lwd = 2)
abline(h = 0.5, col = "red3", lty = 2)
legend("bottomleft", c("R2Y", "Q2"), lwd = 2,
col = c("blue3", "red3"), bty = "n")
A <- 2
mypls = opls(x = X, y = Y, predI = A, crossvalI = nrow(X), scaleC = "standard")
mypred = predict(mypls)
caret::confusionMatrix(mypred, Y)
plot(mypls, typeVc = "x-score",
parAsColFcVn = Y,
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(1:nrow(X)))
par(mfrow = c(1,2))
plot(x = mypls, typeVc = "x-score",
parAsColFcVn = Y,                   # Colorear por grupo
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(Y),         # Etiquetar con valores de clase
parPaletteVc = NA,
parTitleL = TRUE,
parCexMetricN = NA)
plot(x = mypls, typeVc = "x-loading",
parCexN = 0.8, parCompVi = c(1, 2), parPaletteVc = NA,
parTitleL = TRUE, parCexMetricN = NA)
data_plot <- rbind(data.frame(mypls@weightStarMN, space = "X"),
data.frame(mypls@cMN, space = "Y"))
data_plot <- cbind(data_plot, variable = rownames(data_plot))
ggplot(data_plot, aes(x = p1, y = p2, col = space, shape = space)) +
geom_point() +
geom_text_repel(label=rownames(data_plot), size = 3, max.overlaps = Inf) +
xlim(min(data_plot$p1)-0.2,max(data_plot$p1)+0.2) +
ylim(min(data_plot$p2)-0.2,max(data_plot$p2)+0.2) +
coord_fixed(ratio = 1) +
theme_bw() +
geom_vline(xintercept = 0) +
geom_hline(yintercept = 0) +
xlab("w*c (comp 1)") +
ylab("w*c (comp 2)")
# Obtener VIPs y seleccionar las top 20
vip <- sort(mypls@vipVn, decreasing = TRUE)
top_vip_names <- names(vip)[1:20]
# Crear data_plot para X y Y
data_plot <- rbind(
data.frame(mypls@weightStarMN, space = "X"),
data.frame(mypls@cMN, space = "Y")
)
data_plot$variable <- rownames(data_plot)
colnames(data_plot)[1:2] <- c("p1", "p2")
# Filtrar solo las X de interés + todas las Y
data_plot_top <- subset(data_plot, (space == "Y") | (space == "X" & variable %in% top_vip_names))
# Graficar solo variables relevantes
ggplot(data_plot_top, aes(x = p1, y = p2, col = space, shape = space)) +
geom_point() +
geom_text_repel(aes(label = variable), size = 3, max.overlaps = Inf) +
xlim(min(data_plot$p1) - 0.2, max(data_plot$p1) + 0.2) +
ylim(min(data_plot$p2) - 0.2, max(data_plot$p2) + 0.2) +
coord_fixed(ratio = 1) +
theme_bw() +
geom_vline(xintercept = 0) +
geom_hline(yintercept = 0) +
xlab("w*c (comp 1)") +
ylab("w*c (comp 2)") +
ggtitle("Biplot: top 20 X variables by VIP")
# Obtener variables con VIP > 1
# Extraer VIPs
vip <- mypls@vipVn
# Crear data.frame ordenado
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
# Ordenar de mayor a menor
vip_df <- vip_df[order(-vip_df$VIP), ]
# Mostrar
head(vip_df,50)  # muestra las 20 más importantes
# Si aún no existe:
vip <- mypls@vipVn
vip_df <- data.frame(
variable = names(vip),
VIP = as.numeric(vip)
)
vip_df <- vip_df[order(-vip_df$VIP), ]
# (Opcional) Limitar a las 20 más importantes
vip_top <- head(vip_df, 20)
vip_top$variable <- factor(vip_top$variable, levels = vip_top$variable)  # para ordenar bien
# Gráfico bonito
ggplot(vip_top, aes(x = variable, y = VIP)) +
geom_col(fill = "steelblue") +
geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
coord_flip() +
labs(title = "Top 20 variables por VIP",
x = "", y = "Valor VIP") +
theme_minimal(base_size = 13) +
theme(axis.text.y = element_text(size = 12),
plot.title = element_text(hjust = 0.5))
# Seleccionar nombres de variables con VIP > 1
vars_vip_1 <- vip_df$variable[vip_df$VIP > 1]
# Suponiendo que 'data' es tu dataframe original con Y incluida
# Elimina las variables de respuesta
X_vip <- data[, vars_vip_1]
X_vip <- as.matrix(X_vip)
# Preparar Y
Y <- as.factor(data$X1ª_eval)
# Modelo PLS-DA con solo las VIP > 1
pls_vip <- opls(x = X_vip, y = Y,
crossvalI = nrow(X_vip),  # Leave-One-Out CV
scaleC = "standard",
predI = 2)
library(openxlsx)
# Crear data.frame con variables y valores VIP
vip_export <- vip_df[vip_df$VIP > 1, ]
# Guardar en un archivo Excel
write.xlsx(vip_export, "VIP_mayor_1.xlsx", row.names = FALSE)
par(mfrow = c(1,2))
plot(x = pls_vip, typeVc = "x-score",
parAsColFcVn = Y,                   # Colorear por grupo
parCexN = 0.8,
parCompVi = c(1, 2),
parEllipsesL = TRUE,
parLabVc = as.character(Y),         # Etiquetar con valores de clase
parPaletteVc = NA,
parTitleL = TRUE,
parCexMetricN = NA)
plot(x = pls_vip, typeVc = "x-loading",
parCexN = 0.8, parCompVi = c(1, 2), parPaletteVc = NA,
parTitleL = TRUE, parCexMetricN = NA)
mypred_Vip = predict(pls_vip)
library(caret)
caret::confusionMatrix(mypred_Vip, Y, positive = "M")
library(openxlsx)
# Cargar las variables VIP > 1 desde Excel
vip_vars <- read.xlsx("VIP_mayor_1.xlsx")
# Extraer nombres de variables
vip_names <- vip_vars$variable
# Preparar los datos con solo esas variables
X_vip <- data[, vip_names]
Y <- as.factor(data$X1ª_eval)
df_vip <- data.frame(Y, X_vip)
library(openxlsx)
# Cargar las variables VIP > 1 desde Excel
vip_vars <- read.xlsx("VIP_mayor_1.xlsx")
# Extraer nombres de variables
vip_names <- vip_vars$variable
# Preparar los datos con solo esas variables
X_vip <- data[, vip_names]
Y <- as.factor(data$X1ª_eval)
df_vip <- data.frame(Y, X_vip)
library(caret)
set.seed(123)
modelo_lda_vip <- train(
Y ~ .,
data = df_vip,
method = "lda",
trControl = trainControl(method = "LOOCV", classProbs = TRUE, savePredictions = "final")
)
# Evaluar resultados
print(modelo_lda_vip)
confusionMatrix(modelo_lda_vip$pred$pred, modelo_lda_vip$pred$obs)
